{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.transtats.bts.gov/Fields.asp?Table_ID=236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division #, print_function # Imports from __future__ since we're running Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "random_state = 0\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from helpers.feature_engineering import dateStrToDayYear, getMappingOfSimilarCategoricalColumns, \\\n",
    "    compareSimilarCategoricalColumns \n",
    "from helpers.my_one_hot_encoder import MyOneHotEncoder\n",
    "from helpers.py_helpers import is_number\n",
    "from scipy.stats import skew, kurtosis\n",
    "from helpers.outliers import MyOutliers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from helpers.plot_helper import scatter_2d_label\n",
    "from sklearn.decomposition import PCA # Import the PCA module\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import Isomap\n",
    "from helpers.performance_issues import subsample_keeping_class_proportions\n",
    "from flights_delay.feature_processing import FlightDelayFeatureProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flying to New York City - Use all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_col = 'IS_DELAYED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/student/pligor.george@gmail.com/msc_Artificial_Intelligence/dme_Data_Mining/dmedatarats/Data/train_data.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = os.path.realpath(os.path.join(os.getcwd(), '../Data', 'train_data.csv'))\n",
    "assert os.path.isfile(path_data)\n",
    "path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433495, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_data, delimiter = ',', header=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433495, 539)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc = FlightDelayFeatureProcessing().process_all(df)\n",
    "df_proc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433495, 538)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = df_proc.drop(labels=[target_col], axis=1)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy = df_proc[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a first approach we are NOT removing the outliers as we are going to let the isolation forest discover them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outlier_cols = np.array(['DEP_DELAY', 'DISTANCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEP_DELAY    (-114.914854646, 140.381149451)\n",
       "DISTANCE     (-2701.60422982, 4813.45740887)\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = XX[outlier_cols].dtypes\n",
    "for col in outlier_cols:\n",
    "    types[col] = MyOutliers().getLooseBoundaries(XX[col], k=3.0)\n",
    "bounds = types.copy()\n",
    "\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEP_DELAY    9993\n",
       "DISTANCE      659\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlierCounter = MyOutliers.countOutliersDataPoints(XX, bounds)\n",
    "outlierCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only a relatively small number of instances are being held as outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fact only the 2.45723710769 % is being held as outliers\n"
     ]
    }
   ],
   "source": [
    "print \"in fact only the {} % is being held as outliers\".format(100 *np.sum(outlierCounter) / len(XX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QUARTER',\n",
       " 'MONTH',\n",
       " 'DAY_OF_MONTH',\n",
       " 'DAY_OF_WEEK',\n",
       " 'FL_NUM',\n",
       " 'DEP_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'DEP_DELAY_GROUP',\n",
       " 'DISTANCE',\n",
       " 'DISTANCE_GROUP',\n",
       " 'YDAY']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_hot_cols = [col for col in XX.columns if not is_number(col[-1])]\n",
    "not_hot_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xss = XX.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xss[not_hot_cols] = StandardScaler().fit_transform(XX[not_hot_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433495, 539)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.concat( (Xss, yy), axis=1)\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.to_csv(\n",
    "    os.path.realpath(os.path.join(os.getcwd(), '../Data', 'train_data_numerical_normalized.csv')),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dme]",
   "language": "python",
   "name": "Python [dme]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
